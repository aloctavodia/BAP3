| Page | Printed text | Correct text | Thanks |
|------|--------------|--------------|------|
| 13 | The binomial coefficient is typeset as $\left(\frac{n}{x}\right)$ | it should be $\left(n\atop{}x\right)$ | Chris Hansen |
| 62 | We will explore the value **of** over a grid of 200 points. |  We will explore the value over a grid of 200 points.| dweights |
| 88 (exercise 4) | wrong  short url  | The link should point to https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#case-study-2-coal-mining-disasters  | DrEntropy |
| 94 | ...the variance between observed and theoretical values should be the same for all groups.| ...the variance between observed and theoretical values should be unique for each group. |  Kenji Oman  |
| 104 | Figure 3.6 indicates a HalfNormal |  Figure 3.6 should indicate a Gamma | Jacob Warren  |
| 115 | We are going to *usetemperature* | We are going to *use temperature* | Kenji Oman |
| 115 | The noise term is ğœ– | The noise term is ğœ | Parrenin FrÃ©dÃ©ric |
| 116 | We **commit** it because otherwise... | We **omit** it because otherwise... | Kenji Oman |
| 122  | The variance of the NegativeBinomial is ğœ‡ + ğœ‡Â²/ğ›¼ , so the larger the value of ğ›¼ the **larger** the variance. | The variance of the NegativeBinomial is ğœ‡ + ğœ‡Â²/ğ›¼ , so the larger the value of ğ›¼ the **smaller** the variance.     |  TomÃ¡s Capretto  |
| 124 | (or data with a few bulk points)  | (or data with **only** a few bulk points) | Kenji Oman |
| 133 | We have been using the linear motif to model the mean of a distribution **and, in the previous section, we used it to model interactions.** In statistics,... | We have been using the linear motif to model the mean of a distribution.  In statistics,...  | Jacob Warren |
| 145  | In **the next chapter**, we will learn more about linear regression... | In **Chapter 6**, we will learn more about linear regression... | TomÃ¡s Capretto |
|  191 |  The utility of **plot_cap** ... | The utility of **plot_predictions**... | TomÃ¡s Capretto  |
| 194 | model_poly4 = bmb.Model("rented âˆ¼ poly(**temperature**, degree=4)", bikes, | model_poly4 = bmb.Model("rented âˆ¼ poly(**hour**, degree=4)", bikes, | Jacob Warren |
| 195 | Figure 6.5: Posterior mean and posterior predictive distribution for the **bikes model with temperature and humidity** | Figure 6.5: Posterior mean and posterior predictive distribution for the **polynomial bikes models with hour**. | Jacob Warren |
|  207 | We have been using **bmb.interpret_plot_predictions** ... One of them is **bmb.interpret_plot_comparisons**. | We have been using **bmb.interpret.plot_predictions** ... One of them is **bmb.interpret.plot_comparisons**.|  TomÃ¡s Capretto  |
| 208  | Another useful function is **bmb.interpret_plot_slopes** | Another useful function is **bmb.interpret.plot_slopes**  |  TomÃ¡s Capretto |
| 254 | We call **ğœ™** the inverse link function and ğœ™ is... | We call **ğœ“** the inverse link function and ğœ™ is... | Jacob Warren |


Note: on page 23, Figure 1.9 shows the kurtosis. What PreliZ actually computes is the "excess kurtosis", i.e the kurtosis -3. Thanks to Narinder Singh for pointing this out.